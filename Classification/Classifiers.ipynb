{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0b9121b",
   "metadata": {},
   "source": [
    "In this notebook we evaluate each of the following classification models:\n",
    "\n",
    "1. Logistic regression (for classification)\n",
    "2. Support vector classification\n",
    "3. Decision tree classification\n",
    "4. Random forest classification\n",
    "5. k-nearest neighbours classification\n",
    "6. AdaBoost classification\n",
    "7. Gaussian naive Bayes classification\n",
    "8. Neural network classification\n",
    "\n",
    "**Run the code below** to import required packages.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e37ced7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sklearn as sk\n",
    "from sklearn import linear_model, tree, svm, ensemble, neighbors, naive_bayes, neural_network\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, StandardScaler, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold, RandomizedSearchCV, ParameterGrid\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from scipy.io.arff import loadarff\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9f936c",
   "metadata": {},
   "source": [
    "### Data and Classifier Parameters  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "576b339e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Relative path root for datasets\n",
    "file_loc = os.path.join(os.getcwd(),'Datasets/')\n",
    "\n",
    "#Dataset files and parameters based on descriptions\n",
    "dataset_details = {\n",
    "    'credit':\n",
    "        {\n",
    "            'file': ['default of credit card clients.xls'],\n",
    "            'load_params': {\n",
    "                'index_col': 0,\n",
    "                'skiprows': 1\n",
    "            }\n",
    "        },\n",
    "    'breast_cancer':\n",
    "        {\n",
    "            'file': ['breast-cancer-wisconsin.data'],\n",
    "            'load_params': {\n",
    "                'na_values': '?',\n",
    "                'index_col': 0\n",
    "            }\n",
    "        },\n",
    "    'statlog':\n",
    "        {\n",
    "            'file': ['german.data-numeric'],\n",
    "            'load_params': {\n",
    "                'delim_whitespace': 'true'\n",
    "            }\n",
    "        },\n",
    "    'adult':\n",
    "        {\n",
    "            'file': ['adult.data','adult.test'],\n",
    "            'load_params': {\n",
    "                'na_values': '?',\n",
    "                'comment': '|'\n",
    "            }\n",
    "        },\n",
    "    'yeast': {\n",
    "        'file': ['yeast.data'],\n",
    "        'load_params': {\n",
    "            'index_col': 0,\n",
    "            'delim_whitespace': 'true'\n",
    "        }\n",
    "    },\n",
    "    'thoracic': {\n",
    "        'file': ['ThoraricSurgery.arff'],\n",
    "        'load_params': {}\n",
    "    },\n",
    "    'seismic': {\n",
    "        'file': ['seismic-bumps.arff'],\n",
    "        'load_params': {}\n",
    "    },\n",
    "    'retinopathy': {\n",
    "        'file': ['messidor_features.arff'],\n",
    "        'load_params': {\n",
    "            'comment': '@'\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Classifiers used and their subset of hyperparameters chosen to test with gridsearch\n",
    "CLASSIFIERS = {\n",
    "    'logreg': {\n",
    "        'clf': linear_model.LogisticRegression,\n",
    "       'param_grid': {\n",
    "            'C' : [100, 10, 1.0, 0.1, 0.01],\n",
    "            'random_state': [0]\n",
    "        },\n",
    "        'params': {\n",
    "            'credit': {'C': 0.1, 'random_state': 0},\n",
    "            'breast_cancer': {'C': 1.0, 'random_state': 0},\n",
    "            'statlog': {'C': 1.0, 'random_state': 0},\n",
    "            'adult': {'C': 0.1, 'random_state': 0},\n",
    "            'yeast': {'C': 0.1, 'random_state': 0},\n",
    "            'thoracic': {'C': 0.01, 'random_state': 0},\n",
    "            'seismic': {'C': 100, 'random_state': 0},\n",
    "            'retinopathy': {'C': 0.1, 'random_state': 0}\n",
    "        }\n",
    "    },\n",
    "    'tree': {\n",
    "        'clf': tree.DecisionTreeClassifier,\n",
    "        'param_grid': {\n",
    "            'min_samples_split': [2, 5, 10],\n",
    "            'max_depth': [5,10,20,50,100,None],\n",
    "            'random_state': [0]\n",
    "        },\n",
    "        'params': {\n",
    "            'credit':{'max_depth': 5, 'min_samples_split': 2, 'random_state': 0},\n",
    "            'breast_cancer':{'max_depth': 5, 'min_samples_split': 2, 'random_state': 0},\n",
    "            'statlog':{'max_depth': 5, 'min_samples_split': 10, 'random_state': 0},\n",
    "            'adult':{'max_depth': 5, 'min_samples_split': 2, 'random_state': 0},\n",
    "            'yeast': {'max_depth': 5, 'min_samples_split': 10, 'random_state': 0},\n",
    "            'thoracic':{'max_depth': 5, 'min_samples_split': 2, 'random_state': 0},\n",
    "            'seismic':{'max_depth': 5, 'min_samples_split': 10, 'random_state': 0},\n",
    "            'retinopathy':{'max_depth': 10, 'min_samples_split': 5, 'random_state': 0} \n",
    "        }\n",
    "    },\n",
    "    'kneighbors': {\n",
    "        'clf': neighbors.KNeighborsClassifier,\n",
    "        'param_grid': {\n",
    "            'leaf_size': [1,5,10,20,50],\n",
    "            'n_neighbors': [1,5,10,20,30],\n",
    "            'p': [1,2]\n",
    "        },\n",
    "        'params': {\n",
    "        'credit':{'leaf_size': 1, 'n_neighbors': 30, 'p': 2},\n",
    "        'breast_cancer':{'leaf_size': 1, 'n_neighbors': 10, 'p': 2},\n",
    "        'statlog':{'leaf_size': 1, 'n_neighbors': 20, 'p': 2},\n",
    "        'adult':{'leaf_size': 1, 'n_neighbors': 10, 'p': 1},\n",
    "        'yeast': {'leaf_size': 1, 'n_neighbors': 10, 'p': 1},\n",
    "        'thoracic':{'leaf_size': 1, 'n_neighbors': 10, 'p': 1},\n",
    "        'seismic':{'leaf_size': 1, 'n_neighbors': 30, 'p': 1},\n",
    "        'retinopathy':{'leaf_size': 1, 'n_neighbors': 20, 'p': 1}\n",
    "        }\n",
    "    },\n",
    "    'adaboost': {\n",
    "        'clf': ensemble.AdaBoostClassifier,\n",
    "        'param_grid': {\n",
    "            'n_estimators': [10, 50, 100, 500],\n",
    "            'learning_rate': [0.0001, 0.001, 0.01, 0.1, 1.0],\n",
    "            'random_state': [0]\n",
    "            },\n",
    "        'params': {\n",
    "            'credit':{'learning_rate': 0.0001, 'n_estimators': 10},\n",
    "            'breast_cancer':{'learning_rate': 0.1, 'n_estimators': 50},\n",
    "            'statlog':{'learning_rate': 0.1, 'n_estimators': 500},\n",
    "            'adult':{'learning_rate': 0.1, 'n_estimators': 10},\n",
    "            'yeast':{'learning_rate': 1.0, 'n_estimators': 10},\n",
    "            'thoracic':{'learning_rate': 0.01, 'n_estimators': 500},\n",
    "            'seismic':{'learning_rate': 0.0001, 'n_estimators': 10},\n",
    "            'retinopathy':{'learning_rate': 0.1, 'n_estimators': 500}\n",
    "        }\n",
    "    },\n",
    "    'forest': {\n",
    "        'clf': ensemble.RandomForestClassifier,\n",
    "        'param_grid': {\n",
    "            'max_depth': [5, 10, 20, 50, 100, None],\n",
    "            'min_samples_split': [2, 5, 10],\n",
    "            'n_estimators': [100, 500, 1000, 1500, 2000]\n",
    "        },\n",
    "        'params': {\n",
    "            'credit':{'max_depth': 10, 'min_samples_split': 2},\n",
    "            'breast_cancer':{'max_depth': 10, 'min_samples_split': 10},\n",
    "            'statlog':{'max_depth': 50, 'min_samples_split': 2},\n",
    "            'adult':{'max_depth': 20, 'min_samples_split': 5},\n",
    "            'yeast': {'max_depth': 10, 'min_samples_split': 5},\n",
    "            'thoracic':{'max_depth': 5, 'min_samples_split': 2},\n",
    "            'seismic':{'max_depth': 10, 'min_samples_split': 5},\n",
    "            'retinopathy':{'max_depth': 20, 'min_samples_split': 2}\n",
    "            }\n",
    "    },  \n",
    "    'nb': {\n",
    "        'clf': naive_bayes.GaussianNB,\n",
    "        'param_grid': {},\n",
    "        'params': {\n",
    "            'credit': {},\n",
    "            'breast_cancer': {},\n",
    "            'statlog': {},\n",
    "            'adult': {},\n",
    "            'yeast': {},\n",
    "            'thoracic': {},\n",
    "            'seismic': {},\n",
    "            'retinopathy': {} \n",
    "\n",
    "        }\n",
    "    },\n",
    "    'svc': {\n",
    "        'clf': svm.SVC, \n",
    "        'param_grid': {\n",
    "            'kernel': ['rbf'],\n",
    "            'C': [50, 10, 1.0, 0.1, 0.01]\n",
    "        },\n",
    "        'params': {\n",
    "        'credit':{'C': 1.0, 'kernel': 'rbf'},\n",
    "        'breast_cancer':{'C': 1.0, 'kernel': 'rbf'},\n",
    "        'statlog':{'C': 1.0, 'kernel': 'rbf'},\n",
    "        'adult':{'C': 1.0, 'kernel': 'rbf'},\n",
    "        'yeast':{'C': 1.0, 'kernel': 'rbf'},\n",
    "        'thoracic':{'C': 1.0, 'kernel': 'rbf'},\n",
    "        'seismic':{'C': 1.0, 'kernel': 'rbf'},\n",
    "        'retinopathy':{'C': 1.0, 'kernel': 'rbf'}\n",
    "        }\n",
    "    },\n",
    "    'neural': {\n",
    "        'clf': neural_network.MLPClassifier,\n",
    "        'param_grid': {\n",
    "            'hidden_layer_sizes': [(50,50,50), (50,100,50), (100,)],\n",
    "            'activation': ['tanh', 'relu'],\n",
    "            'solver': ['sgd', 'adam'],\n",
    "            'alpha': [0.0001, 0.05],\n",
    "            'learning_rate': ['constant','adaptive'],\n",
    "            'max_iter': [100]\n",
    "        },\n",
    "        'params': {\n",
    "            'credit':{'activation': 'relu', 'hidden_layer_sizes': (100,), 'max_iter': 500},\n",
    "            'breast_cancer':{'activation': 'relu', 'hidden_layer_sizes': (100,), 'max_iter': 500},\n",
    "            'statlog':{'activation': 'tanh', 'hidden_layer_sizes': (100,), 'max_iter': 500},\n",
    "            'adult':{'activation': 'tanh', 'hidden_layer_sizes': (100,), 'max_iter': 500},\n",
    "            'yeast': {'activation': 'tanh', 'hidden_layer_sizes': (100,), 'max_iter': 500},\n",
    "            'thoracic':{'activation': 'tanh', 'hidden_layer_sizes': (100,), 'max_iter': 500},\n",
    "            'seismic':{'activation': 'tanh', 'hidden_layer_sizes': (100,), 'max_iter': 500},\n",
    "            'retinopathy': {'activation': 'tanh', 'hidden_layer_sizes': (50, 50, 50), 'max_iter': 500}\n",
    "        }\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e2a72a",
   "metadata": {},
   "source": [
    "### Preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4d6b76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessor(dataset_details, file_loc, strategy='mean', encoder=StandardScaler, gridsearchflag=False):\n",
    "\n",
    "    '''\n",
    "    Loads all datasets in\n",
    "    Standardizes to dataframe\n",
    "    Splits into train and testing data\n",
    "    '''\n",
    "\n",
    "    train_data = {}\n",
    "    test_data = {}\n",
    "\n",
    "    for dataset in dataset_details:\n",
    "        if (gridsearchflag==True):\n",
    "            if (dataset!='adult'):\n",
    "                continue\n",
    "        X, y = load_dataset(dataset_details[dataset], file_loc)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "        #Encode categorical values and scale numeric values\n",
    "        X_enc, y_enc = create_encoders(X_train, y_train, encoder)\n",
    "        X_train = X_enc.transform(X_train)\n",
    "        X_test = X_enc.transform(X_test)\n",
    "        \n",
    "        if scipy.sparse.issparse(X_train):\n",
    "            X_train = X_train.toarray()\n",
    "            X_test = X_test.toarray()\n",
    "        if y_enc:\n",
    "            y_train = y_enc.transform(y_train)\n",
    "            y_test = y_enc.transform(y_test)\n",
    "\n",
    "        X_imp, X_train, X_test = impute(X_train, X_test, strategy)\n",
    "\n",
    "        train_data[dataset] = {\n",
    "            'X_train': X_train,\n",
    "            'y_train': y_train,\n",
    "        }\n",
    "        test_data[dataset] = {\n",
    "            'X_test': X_test,\n",
    "            'y_test': y_test,\n",
    "            'X_imp': X_imp,\n",
    "            'X_enc': X_enc,\n",
    "            'y_enc': y_enc\n",
    "        }\n",
    "\n",
    "    return train_data, test_data\n",
    "\n",
    "def impute(X_train, X_test, strategy='mean'):\n",
    "    imp = SimpleImputer(missing_values=np.nan, strategy=strategy)\n",
    "    X_imp = imp.fit(X_train)\n",
    "    X_train = X_imp.transform(X_train)\n",
    "    X_test = X_imp.transform(X_test)\n",
    "\n",
    "    return X_imp, X_train, X_test\n",
    "\n",
    "def create_encoders(X, y, encoder):\n",
    "\n",
    "    '''\n",
    "    Splits dataset into numerical and categorical data\n",
    "    creates relevant encoders for both features and labels\n",
    "    '''\n",
    "\n",
    "    cat_enc = OneHotEncoder(handle_unknown='ignore')\n",
    "    num_enc = encoder()\n",
    "\n",
    "    cat_features = X.select_dtypes(include=['object']).columns\n",
    "    num_features =X.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "    if len(cat_features)==0:\n",
    "        X_enc = num_enc\n",
    "    elif len(num_features)==0:\n",
    "        X_enc = cat_enc\n",
    "    else:\n",
    "        X_enc = ColumnTransformer(\n",
    "            transformers=[\n",
    "                (\"num\", num_enc, num_features),\n",
    "                (\"cat\", cat_enc, cat_features)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    X_enc.fit(X)\n",
    "    \n",
    "    y_enc = None\n",
    "    if y.dtypes=='object':\n",
    "        y_enc = LabelEncoder().fit(y)\n",
    "\n",
    "\n",
    "    return X_enc, y_enc\n",
    "    \n",
    "def load_dataset(dataset, file_loc):\n",
    "    '''\n",
    "    Loads in a dataset according to type and load_params\n",
    "    Assumes dataset file is either .xls, .arff, or plain text\n",
    "    If test and train are pre-split, assumes they are the same file type and combines for preprocessing.\n",
    "    Separates out the last column as y\n",
    "    '''\n",
    "\n",
    "    #metadata = dataset_details[dataset]\n",
    "    filenames = dataset['file']\n",
    "    load_params = dataset['load_params']\n",
    "\n",
    "    dfs = []\n",
    "    for file in filenames:\n",
    "        extension = file.split('.')[1]  # Get file type\n",
    "        file = f'{file_loc}{file}'\n",
    "        if extension == 'xls':\n",
    "            df = load_excel(file, **load_params)\n",
    "        elif extension == 'arff':\n",
    "            df = load_arff(file)\n",
    "        else:\n",
    "            df = load_plaintext(file, **load_params)\n",
    "        dfs.append(df)\n",
    "        df = pd.concat(dfs)\n",
    "    \n",
    "    y = df.iloc[:,-1]\n",
    "    X = df = df.iloc[: , :-1]\n",
    "\n",
    "    return X, y\n",
    "\n",
    "def load_excel(file,  **kwargs):\n",
    "    df = pd.read_excel(file, dtype=None, engine='xlrd', **kwargs)\n",
    "    return df\n",
    "\n",
    "def load_arff(file):\n",
    "    data = loadarff(file)\n",
    "    df = pd.DataFrame(data[0])\n",
    "    return df\n",
    "\n",
    "def load_plaintext(file, **kwargs):\n",
    "    df = pd.read_csv(file, header=None, dtype=None, **kwargs)\n",
    "    return df\n",
    "\n",
    "train_data, test_data = preprocessor(dataset_details, file_loc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f66a57",
   "metadata": {},
   "source": [
    "### Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e741571",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run time : Approx 7 mins\n",
    "\n",
    "def train_classifiers(data, CLASSIFIERS, gridsearchflag=False):\n",
    "\n",
    "    '''\n",
    "    Trains every classifier on every dataset\n",
    "    '''\n",
    "\n",
    "    models = {}\n",
    "    for clf in CLASSIFIERS:\n",
    "        models[clf]={}\n",
    "        for dataset in data:\n",
    "            if (gridsearchflag==True):\n",
    "                if (dataset!='adult'): continue\n",
    "            #print(\"Training \",clf,\" on \",dataset)\n",
    "            model = train_clf(CLASSIFIERS[clf], data[dataset]['X_train'], data[dataset]['y_train'], **CLASSIFIERS[clf]['params'][dataset])\n",
    "            models[clf][dataset] = {\n",
    "                'model': model\n",
    "            }\n",
    "        \n",
    "\n",
    "    return models\n",
    "\n",
    "def train_clf(clf_data, X, y, **params):\n",
    "\n",
    "    '''\n",
    "    Trains a given classifier on a given dataset\n",
    "    '''\n",
    "    clf = clf_data['clf']\n",
    "    model = clf(**params).fit(X,y)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "models = train_classifiers(train_data, CLASSIFIERS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987c2ab9",
   "metadata": {},
   "source": [
    "### Choose Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea4593a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run time: Approx 12 minutes\n",
    "\n",
    "def find_hyperparams(classifier_details, dataset, X, y, gridsearch):\n",
    "    params = classifier_details['params'][dataset]\n",
    "    model = classifier_details['clf'](**params)\n",
    "    param_grid = classifier_details['param_grid']\n",
    "    cv = KFold(n_splits=5)\n",
    "    search = gridsearch(model, param_grid, cv=cv, n_jobs=-1)\n",
    "\n",
    "    result = search.fit(X, y)\n",
    "    classifier_details['params'][dataset]=result.best_params_\n",
    "\n",
    "def find_all_hyperparams(data, classifiers, datasets, gridsearch=GridSearchCV, gridsearchflag=True):\n",
    "    count = 0\n",
    "    for clf in classifiers:\n",
    "        for dataset in datasets:\n",
    "            if (gridsearchflag==True):\n",
    "                if (dataset!='yeast'): continue\n",
    "            find_hyperparams(classifiers[clf], dataset, data[dataset]['X_train'], data[dataset]['y_train'], gridsearch)\n",
    "        count+=1\n",
    "\n",
    "find_all_hyperparams(train_data,CLASSIFIERS, dataset_details)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083cb67f",
   "metadata": {},
   "source": [
    "### Test Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f795d4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run time: Approx 3 minutes\n",
    "\n",
    "def test_classifiers(data, models, scoring=f1_score, gridsearchflag=False):\n",
    "    scores = {}\n",
    "\n",
    "    for clf in models:\n",
    "        scores[clf] = []\n",
    "        for dataset in models[clf]:\n",
    "            if (gridsearchflag==True):\n",
    "                if (dataset!='yeast'): continue\n",
    "            score = test_clf(models[clf][dataset], data[dataset], scoring)\n",
    "            scores[clf].append(score)\n",
    "\n",
    "    scores = pd.DataFrame.from_dict(scores,orient='index',columns=dataset_details.keys())\n",
    "    np.set_printoptions(edgeitems=3)\n",
    "    np.core.arrayprint._line_width = 100\n",
    "    print (scores)\n",
    "            \n",
    "\n",
    "def test_clf(models, test_data, scoring):\n",
    "    model = models['model']\n",
    "    X = test_data['X_test']\n",
    "    y = test_data['y_test']\n",
    "\n",
    "    X = test_data['X_imp'].transform(X)\n",
    "    \n",
    "    if scipy.sparse.issparse(X):\n",
    "        X = X.toarray()\n",
    "    if models.get('y_enc'):\n",
    "        y = models['y_enc'].transform(y)\n",
    "    \n",
    "    y_pred = model.predict(X)\n",
    "\n",
    "    if (scoring==f1_score):\n",
    "        score = f1_score(y,y_pred,average='micro')\n",
    "    else:\n",
    "        score = model.score(y,y_pred)\n",
    "    \n",
    "    return round(score,2)\n",
    "\n",
    "test_classifiers(test_data, models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6769b57e",
   "metadata": {},
   "source": [
    "### Decision Gridsearch (Novelty Component)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373261cd",
   "metadata": {},
   "source": [
    "The aim of a \"decision gridsearch\" is to analyze the decisions made at every step of preprocessing, training and testing, to determine if what we as students thought made sense actually corresponds to the highest scores. While we can't try every decision or every possibility for a given decision, the goal is to give some insight as to what kind of decisions need to have more thought put into them and what kind have minimal impact on a given type of dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7997e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_dataset = 'adult' #Chose a dataset that had particularly low scores to begin with \n",
    "\n",
    "decisions = {\n",
    "    'strategy': ['mean','most_frequent'],\n",
    "    'scaler': [MinMaxScaler, StandardScaler],\n",
    "    'gridsearch': [GridSearchCV, RandomizedSearchCV],\n",
    "    'scoring': [f1_score, 'score']\n",
    "}\n",
    "\n",
    "combinations = ParameterGrid(decisions)\n",
    "\n",
    "for combination in combinations:\n",
    "    strategy = combination['strategy']\n",
    "    scaler = combination['scaler']\n",
    "    gridsearch = combination['gridsearch']\n",
    "    scoring = combination['scoring']\n",
    "    print(strategy, scaler, gridsearch, scoring)\n",
    "    train_data_yeast, test_data_yeast = preprocessor(dataset_details, file_loc, strategy=strategy, encoder=scaler, gridsearchflag=True)\n",
    "    models = train_classifiers(train_data, CLASSIFIERS)\n",
    "    #find_all_hyperparams(train_data_yeast, models, CLASSIFIERS, gridsearch=gridsearch, gridsearchflag=True)\n",
    "    test_classifiers(test_data, models, gridsearchflag=True)\n",
    "    \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
