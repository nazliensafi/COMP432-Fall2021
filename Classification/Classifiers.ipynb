{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0b9121b",
   "metadata": {},
   "source": [
    "# 1. Default of credit card clients:\n",
    "\n",
    "In this notebook we evaluate each of the following classification models on *default of credit card clients* dataset.\n",
    "\n",
    "1. Logistic regression (for classification)\n",
    "2. Support vector classification\n",
    "3. Decision tree classification\n",
    "4. Random forest classification\n",
    "5. k-nearest neighbours classification\n",
    "6. AdaBoost classification\n",
    "7. Gaussian naive Bayes classification\n",
    "8. Neural network classification\n",
    "\n",
    "**Run the code below** to import required packages.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e37ced7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn as sk\n",
    "from sklearn import linear_model, tree, svm, ensemble, neighbors, naive_bayes, neural_network\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.io.arff import loadarff\n",
    "import pandas as pd\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9f936c",
   "metadata": {},
   "source": [
    "### Data and Classifier Parameters  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "576b339e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Relative path root for datasets\n",
    "file_loc = 'Classification\\\\Datasets\\\\'\n",
    "\n",
    "#Dataset files and parameters based on descriptions\n",
    "dataset_details = {\n",
    "    'credit':\n",
    "        {\n",
    "            'file': ['default of credit card clients.xls'],\n",
    "            'load_params': {\n",
    "                'index_col': 0,\n",
    "                'skiprows': 1\n",
    "            }\n",
    "        },\n",
    "    'breast_cancer':\n",
    "        {\n",
    "            'file': ['breast-cancer-wisconsin.data'],\n",
    "            'load_params': {\n",
    "                'na_values': '?',\n",
    "                'index_col': 0\n",
    "            },\n",
    "            'weighted': 'Y'\n",
    "        },\n",
    "    'statlog':\n",
    "        {\n",
    "            'file': ['german.data-numeric'],\n",
    "            'load_params': {\n",
    "                'delim_whitespace': 'true'\n",
    "            },\n",
    "            'weighted': 'Y',\n",
    "        },\n",
    "    'adult':\n",
    "        {\n",
    "            'file': ['adult.data','adult.test'],\n",
    "            'load_params': {\n",
    "                'na_values': '?',\n",
    "                'comment': '|'\n",
    "            }\n",
    "        },\n",
    "    'yeast': {\n",
    "        'file': ['yeast.data'],\n",
    "        'load_params': {\n",
    "            'index_col': 0,\n",
    "            'delim_whitespace': 'true'\n",
    "        }\n",
    "    },\n",
    "    'thoracic': {\n",
    "        'file': ['ThoraricSurgery.arff'],\n",
    "        'load_params': {}\n",
    "    },\n",
    "    'seismic': {\n",
    "        'file': ['seismic-bumps.arff'],\n",
    "        'load_params': {}\n",
    "    },\n",
    "    'retinopathy': {\n",
    "        'file': ['messidor_features.arff'],\n",
    "        'load_params': {\n",
    "            'comment': '@'\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Classifiers used - params will be filled in with the chosen hyperparameters\n",
    "CLASSIFIERS = {\n",
    "    'logreg': {\n",
    "        'clf': linear_model.LogisticRegression,\n",
    "        'params': {}\n",
    "    },\n",
    "    'tree': {\n",
    "        'clf': tree.DecisionTreeClassifier,\n",
    "        'params': {}\n",
    "    },\n",
    "    'kneighbors': {\n",
    "        'clf': neighbors.KNeighborsClassifier,\n",
    "        'params': {}\n",
    "    },\n",
    "    'adaboost': {\n",
    "        'clf': ensemble.AdaBoostClassifier,\n",
    "        'params': {}\n",
    "    },\n",
    "    'nb': {\n",
    "        'clf': naive_bayes.GaussianNB,\n",
    "        'params': {}\n",
    "    },\n",
    "    'forest': {\n",
    "        'clf': ensemble.RandomForestClassifier,\n",
    "        'params': {}\n",
    "    },\n",
    "    'neural': {\n",
    "        'clf': neural_network.MLPClassifier,\n",
    "        'params': {}\n",
    "    },\n",
    "    'svc': {\n",
    "        'clf': svm.SVC,\n",
    "        'params': {}\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e2a72a",
   "metadata": {},
   "source": [
    "### Preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4d6b76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessor(dataset_details, file_loc):\n",
    "\n",
    "    '''\n",
    "    Loads all datasets in\n",
    "    Standardizes to dataframe\n",
    "    Splits into train and testing data\n",
    "    '''\n",
    "\n",
    "    train_data = {}\n",
    "    test_data = {}\n",
    "\n",
    "    for dataset in dataset_details:\n",
    "        X, y = load_dataset(dataset_details[dataset], file_loc)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "        if dataset=='breast_cancer': \n",
    "            X_train = X_train.fillna(value=10)\n",
    "            X_test = X_test.fillna(value=10)\n",
    "\n",
    "        train_data[dataset] = {\n",
    "            'X_train': X_train,\n",
    "            'y_train': y_train\n",
    "        }\n",
    "        test_data[dataset] = {\n",
    "            'X_test': X_test,\n",
    "            'y_test': y_test\n",
    "        }\n",
    "\n",
    "    return train_data, test_data\n",
    "\n",
    "def load_dataset(dataset, file_loc):\n",
    "    '''\n",
    "    Loads in a dataset according to type and load_params\n",
    "    Assumes dataset file is either .xls, .arff, or plain text\n",
    "    If test and train are pre-split, assumes they are the same file type and combines for preprocessing.\n",
    "    Separates out the last column as y\n",
    "    '''\n",
    "\n",
    "    #metadata = dataset_details[dataset] # using dataset_details directly rather than metadata``\n",
    "    filenames = dataset['file']\n",
    "    load_params = dataset['load_params']\n",
    "\n",
    "    dfs = []\n",
    "    for file in filenames:\n",
    "        extension = file.split('.')[1]  # Get file type\n",
    "        file = f'{file_loc}{file}'\n",
    "        if extension == 'xls':\n",
    "            df = load_excel(file, **load_params)\n",
    "        elif extension == 'arff':\n",
    "            df = load_arff(file)\n",
    "        else:\n",
    "            df = load_plaintext(file, **load_params)\n",
    "        dfs.append(df)\n",
    "        df = pd.concat(dfs)\n",
    "    \n",
    "    y = df.iloc[:,-1]\n",
    "    X = df = df.iloc[: , :-1]\n",
    "\n",
    "    return X, y\n",
    "\n",
    "def load_excel(file,  **kwargs):\n",
    "    df = pd.read_excel(file, dtype=None, engine='xlrd', **kwargs)\n",
    "    return df\n",
    "\n",
    "def load_arff(file):\n",
    "    data = loadarff(file)\n",
    "    df = pd.DataFrame(data[0])\n",
    "    df.dropna()\n",
    "    return df\n",
    "\n",
    "def load_plaintext(file, **kwargs):\n",
    "    df = pd.read_csv(file, header=None, dtype=None, **kwargs)\n",
    "    df.dropna()\n",
    "    return df\n",
    "\n",
    "train_data, test_data = preprocessor(dataset_details, file_loc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f66a57",
   "metadata": {},
   "source": [
    "### Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e741571",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifiers(data, CLASSIFIERS):\n",
    "\n",
    "    '''\n",
    "    Trains every classifier on every dataset\n",
    "    '''\n",
    "\n",
    "    models = {}\n",
    "    for clf in CLASSIFIERS:\n",
    "        for dataset in data:\n",
    "            print(\"Training \",clf,\" on \",dataset)\n",
    "            model = train_clf(CLASSIFIERS[clf], data[dataset]['X_train'], data[dataset]['y_train'])\n",
    "            models[clf]={}\n",
    "            models[clf][dataset] = model\n",
    "        \n",
    "\n",
    "    return models\n",
    "\n",
    "def train_clf(clf_data, X, y):\n",
    "\n",
    "    '''\n",
    "    Trains a given classifier on a given dataset\n",
    "    '''\n",
    "    \n",
    "    X_enc, y_enc = encode_or_scale(X, y)\n",
    "    X = X_enc.transform(X)\n",
    "    if scipy.sparse.issparse(X):\n",
    "        X = X.toarray()\n",
    "    if y_enc:\n",
    "        y = y_enc.transform(y)\n",
    "\n",
    "\n",
    "    clf = clf_data['clf']\n",
    "    params = clf_data['params']\n",
    "    model = clf(**params).fit(X,y)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def encode_or_scale(X, y):\n",
    "\n",
    "    '''\n",
    "    Splits dataset into numerical and categorical data\n",
    "    creates relevant encoders for both features and labels\n",
    "    '''\n",
    "\n",
    "    cat_enc = OneHotEncoder(handle_unknown='ignore')\n",
    "    num_enc = MinMaxScaler()\n",
    "\n",
    "    cat_features = X.select_dtypes(include=['object']).columns\n",
    "    num_features =X.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "    if len(cat_features)==0:\n",
    "        X_enc = num_enc\n",
    "    elif len(num_features)==0:\n",
    "        X_enc = cat_enc\n",
    "    else:\n",
    "        X_enc = ColumnTransformer(\n",
    "            transformers=[\n",
    "                (\"num\", num_enc, num_features),\n",
    "                (\"cat\", cat_enc, cat_features)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    X_enc.fit(X)\n",
    "    \n",
    "    y_enc = None\n",
    "    if y.dtypes=='object':\n",
    "        y_enc = LabelEncoder().fit(y)\n",
    "\n",
    "\n",
    "    return X_enc, y_enc\n",
    "    \n",
    "models = train_classifiers(train_data, CLASSIFIERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987c2ab9",
   "metadata": {},
   "source": [
    "### Choose Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea4593a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "083cb67f",
   "metadata": {},
   "source": [
    "### Test Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f795d4f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
